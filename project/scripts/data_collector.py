"""
BTC ä»·æ ¼å˜åŠ¨é¢„æµ‹ - æ•°æ®æ”¶é›†ä¸ç‰¹å¾æå–

åŸºäº KDJ/MACD å¤šæ—¶é—´å‘¨æœŸäº¤å‰ä¿¡å·é¢„æµ‹ä»·æ ¼å˜åŠ¨

åŠŸèƒ½:
1. æ”¶é›†å¤šæ—¶é—´å‘¨æœŸ K çº¿æ•°æ® (5m, 15m, 30m, 1h, 4h, 1d)
2. è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ (KDJ, MACD, RSI, ROC, MOM, Williams %R, CCI, ADX, Stochastic RSI)
3. æ£€æµ‹é‡‘å‰/æ­»å‰ä¿¡å·
4. æå–å¸‚åœºçŠ¶æ€ç‰¹å¾
5. ç”Ÿæˆä»·æ ¼å˜åŠ¨æ ‡ç­¾

ä½¿ç”¨æ–¹æ³•:
    python data_collector.py --symbol BTCUSDT --output ../data
"""

import pandas as pd
import numpy as np
import json
import time
import argparse
import os
from datetime import datetime
from typing import Dict, List, Optional
import urllib.request
import ssl


class BinanceDataFetcher:
    """Binance æ•°æ®è·å–å™¨"""
    
    def __init__(self, symbol: str = 'BTCUSDT'):
        self.symbol = symbol.upper()
        self.base_url = "https://fapi.binance.com"
        
        # SSL é…ç½®ï¼ˆç¦ç”¨è¯ä¹¦éªŒè¯ä»¥è§£å†³æŸäº›ç½‘ç»œç¯å¢ƒçš„é—®é¢˜ï¼‰
        self.ssl_context = ssl.create_default_context()
        self.ssl_context.check_hostname = False
        self.ssl_context.verify_mode = ssl.CERT_NONE
        
        # æ”¯æŒçš„æ—¶é—´å‘¨æœŸ
        self.timeframes = ['5m', '15m', '30m', '1h', '4h', '1d']
    
    def _request(self, endpoint: str, params: dict = None) -> dict:
        """å‘é€ REST API è¯·æ±‚"""
        url = f"{self.base_url}{endpoint}"
        if params:
            query = "&".join([f"{k}={v}" for k, v in params.items()])
            url = f"{url}?{query}"
        
        req = urllib.request.Request(url)
        with urllib.request.urlopen(req, context=self.ssl_context, timeout=30) as response:
            return json.loads(response.read().decode())
    
    def get_klines(self, interval: str, limit: int = 500, 
                    start_time: int = None, end_time: int = None) -> pd.DataFrame:
        """
        è·å– K çº¿æ•°æ®
        
        Args:
            interval: æ—¶é—´å‘¨æœŸ (5m, 15m, 1h, 4h, 1d)
            limit: è·å–çš„ K çº¿æ•°é‡ (å•æ¬¡æœ€å¤§ 1500)
            start_time: å¼€å§‹æ—¶é—´æˆ³ (æ¯«ç§’)
            end_time: ç»“æŸæ—¶é—´æˆ³ (æ¯«ç§’)
            
        Returns:
            DataFrame with columns: timestamp, open, high, low, close, volume
        """
        params = {
            "symbol": self.symbol,
            "interval": interval,
            "limit": min(limit, 1500)  # Binance å•æ¬¡æœ€å¤§ 1500
        }
        
        if start_time:
            params["startTime"] = start_time
        if end_time:
            params["endTime"] = end_time
        
        data = self._request("/fapi/v1/klines", params)
        
        df = pd.DataFrame(data, columns=[
            'timestamp', 'open', 'high', 'low', 'close', 'volume',
            'close_time', 'quote_volume', 'trades', 'taker_buy_base',
            'taker_buy_quote', 'ignore'
        ])
        
        # è½¬æ¢æ•°æ®ç±»å‹
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        for col in ['open', 'high', 'low', 'close', 'volume']:
            df[col] = df[col].astype(float)
        
        return df[['timestamp', 'open', 'high', 'low', 'close', 'volume']]
    
    def get_funding_rate(self) -> dict:
        """è·å–èµ„é‡‘è´¹ç‡"""
        data = self._request("/fapi/v1/premiumIndex", {"symbol": self.symbol})
        return {
            'funding_rate': float(data.get('lastFundingRate', 0)),
            'mark_price': float(data.get('markPrice', 0)),
            'index_price': float(data.get('indexPrice', 0)),
        }
    
    def get_klines_historical(self, interval: str, start_date: str, end_date: str = None) -> pd.DataFrame:
        """
        è·å–å†å² K çº¿æ•°æ®ï¼ˆè‡ªåŠ¨åˆ†æ‰¹è·å–ï¼‰
        
        Args:
            interval: æ—¶é—´å‘¨æœŸ (5m, 15m, 1h, 4h, 1d)
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)ï¼Œé»˜è®¤ä¸ºå½“å‰æ—¶é—´
            
        Returns:
            å®Œæ•´çš„å†å² K çº¿ DataFrame
        """
        from datetime import datetime, timedelta
        
        # è§£ææ—¥æœŸ
        start_dt = datetime.strptime(start_date, "%Y-%m-%d")
        end_dt = datetime.strptime(end_date, "%Y-%m-%d") if end_date else datetime.now()
        
        start_ms = int(start_dt.timestamp() * 1000)
        end_ms = int(end_dt.timestamp() * 1000)
        
        # è®¡ç®—æ¯ä¸ªå‘¨æœŸçš„æ¯«ç§’æ•°
        interval_ms = {
            '5m': 5 * 60 * 1000,
            '15m': 15 * 60 * 1000,
            '1h': 60 * 60 * 1000,
            '4h': 4 * 60 * 60 * 1000,
            '1d': 24 * 60 * 60 * 1000
        }
        
        ms_per_candle = interval_ms.get(interval, 60 * 60 * 1000)
        batch_size = 1000  # æ¯æ‰¹è·å–çš„ K çº¿æ•°
        batch_ms = batch_size * ms_per_candle
        
        all_data = []
        current_start = start_ms
        
        while current_start < end_ms:
            current_end = min(current_start + batch_ms, end_ms)
            
            df = self.get_klines(interval, limit=batch_size, 
                                start_time=current_start, end_time=current_end)
            
            if len(df) == 0:
                break
                
            all_data.append(df)
            
            # ä¸‹ä¸€æ‰¹çš„å¼€å§‹æ—¶é—´
            last_timestamp = df['timestamp'].iloc[-1]
            current_start = int(last_timestamp.timestamp() * 1000) + ms_per_candle
            
            time.sleep(0.1)  # é¿å…è¯·æ±‚è¿‡å¿«
        
        if not all_data:
            return pd.DataFrame()
        
        # åˆå¹¶æ‰€æœ‰æ•°æ®
        result = pd.concat(all_data, ignore_index=True)
        result = result.drop_duplicates(subset=['timestamp']).sort_values('timestamp').reset_index(drop=True)
        
        return result
    
    def get_all_timeframes(self, limit: int = 500) -> Dict[str, pd.DataFrame]:
        """è·å–æ‰€æœ‰æ—¶é—´å‘¨æœŸçš„æ•°æ®"""
        data_dict = {}
        for tf in self.timeframes:
            print(f"  ğŸ“Š è·å– {tf} K çº¿æ•°æ®...")
            data_dict[tf] = self.get_klines(tf, limit)
            time.sleep(0.2)  # é¿å…è¯·æ±‚è¿‡å¿«
        return data_dict
    
    def get_all_timeframes_historical(self, start_date: str, end_date: str = None) -> Dict[str, pd.DataFrame]:
        """è·å–æ‰€æœ‰æ—¶é—´å‘¨æœŸçš„å†å²æ•°æ®"""
        data_dict = {}
        for tf in self.timeframes:
            print(f"  ğŸ“Š è·å– {tf} å†å² K çº¿æ•°æ® ({start_date} ~ {end_date or 'ç°åœ¨'})...")
            data_dict[tf] = self.get_klines_historical(tf, start_date, end_date)
            print(f"      è·å–åˆ° {len(data_dict[tf])} æ ¹ K çº¿")
            time.sleep(0.3)
        return data_dict


class TechnicalIndicators:
    """æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å™¨ï¼ˆä¸ä¾èµ– TA-Libï¼‰"""
    
    @staticmethod
    def calculate_ema(series: pd.Series, period: int) -> pd.Series:
        """è®¡ç®— EMA"""
        return series.ewm(span=period, adjust=False).mean()
    
    @staticmethod
    def calculate_sma(series: pd.Series, period: int) -> pd.Series:
        """è®¡ç®— SMA"""
        return series.rolling(window=period).mean()
    
    @staticmethod
    def calculate_kdj(df: pd.DataFrame, n: int = 9, m1: int = 3, m2: int = 3) -> tuple:
        """
        è®¡ç®— KDJ æŒ‡æ ‡
        
        Args:
            df: åŒ…å« high, low, close çš„ DataFrame
            n: RSV å‘¨æœŸ
            m1: K å€¼å¹³æ»‘å‘¨æœŸ
            m2: D å€¼å¹³æ»‘å‘¨æœŸ
            
        Returns:
            (K, D, J) Series tuple
        """
        low_n = df['low'].rolling(window=n).min()
        high_n = df['high'].rolling(window=n).max()
        
        # RSV = (Close - Low_n) / (High_n - Low_n) * 100
        rsv = (df['close'] - low_n) / (high_n - low_n) * 100
        rsv = rsv.fillna(50)  # å¤„ç† NaN
        
        # K = SMA(RSV, m1)
        k = rsv.ewm(alpha=1/m1, adjust=False).mean()
        
        # D = SMA(K, m2)
        d = k.ewm(alpha=1/m2, adjust=False).mean()
        
        # J = 3K - 2D
        j = 3 * k - 2 * d
        
        return k, d, j
    
    @staticmethod
    def calculate_macd(close: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9) -> tuple:
        """
        è®¡ç®— MACD æŒ‡æ ‡
        
        Args:
            close: æ”¶ç›˜ä»· Series
            fast: å¿«çº¿å‘¨æœŸ
            slow: æ…¢çº¿å‘¨æœŸ
            signal: ä¿¡å·çº¿å‘¨æœŸ
            
        Returns:
            (MACD, Signal, Histogram) Series tuple
        """
        ema_fast = TechnicalIndicators.calculate_ema(close, fast)
        ema_slow = TechnicalIndicators.calculate_ema(close, slow)
        
        macd = ema_fast - ema_slow
        signal_line = TechnicalIndicators.calculate_ema(macd, signal)
        histogram = macd - signal_line
        
        return macd, signal_line, histogram
    
    @staticmethod
    def detect_crossover(fast: pd.Series, slow: pd.Series) -> tuple:
        """
        æ£€æµ‹é‡‘å‰/æ­»å‰
        
        Returns:
            (golden_cross, death_cross) bool Series tuple
        """
        # é‡‘å‰ï¼šå¿«çº¿ä»ä¸‹å¾€ä¸Šç©¿è¶Šæ…¢çº¿
        golden = (fast > slow) & (fast.shift(1) <= slow.shift(1))
        
        # æ­»å‰ï¼šå¿«çº¿ä»ä¸Šå¾€ä¸‹ç©¿è¶Šæ…¢çº¿
        death = (fast < slow) & (fast.shift(1) >= slow.shift(1))
        
        return golden, death
    
    @staticmethod
    def calculate_rsi(close: pd.Series, period: int = 14) -> pd.Series:
        """
        è®¡ç®— RSI (Relative Strength Index) æŒ‡æ ‡
        
        Args:
            close: æ”¶ç›˜ä»· Series
            period: RSI å‘¨æœŸ (é»˜è®¤ 14)
            
        Returns:
            RSI Series (0-100)
        """
        # è®¡ç®—ä»·æ ¼å˜åŠ¨
        delta = close.diff()
        
        # åˆ†ç¦»æ¶¨è·Œ
        gain = delta.where(delta > 0, 0)
        loss = (-delta).where(delta < 0, 0)
        
        # è®¡ç®—å¹³å‡æ¶¨è·Œ (ä½¿ç”¨ EMA)
        avg_gain = gain.ewm(alpha=1/period, adjust=False).mean()
        avg_loss = loss.ewm(alpha=1/period, adjust=False).mean()
        
        # è®¡ç®— RS
        rs = avg_gain / avg_loss
        
        # è®¡ç®— RSI
        rsi = 100 - (100 / (1 + rs))
        
        # å¤„ç†é™¤é›¶æƒ…å†µ
        rsi = rsi.fillna(50)
        rsi = rsi.replace([np.inf, -np.inf], 50)
        
        return rsi
    
    @staticmethod
    def calculate_roc(close: pd.Series, period: int = 10) -> pd.Series:
        """
        è®¡ç®— ROC (Rate of Change) - ä»·æ ¼å˜åŒ–ç‡
        
        Args:
            close: æ”¶ç›˜ä»· Series
            period: è®¡ç®—å‘¨æœŸ
            
        Returns:
            ROC Series (ç™¾åˆ†æ¯”)
        """
        roc = (close - close.shift(period)) / close.shift(period) * 100
        return roc.fillna(0)
    
    @staticmethod
    def calculate_momentum(close: pd.Series, period: int = 10) -> pd.Series:
        """
        è®¡ç®— MOM (Momentum) - åŠ¨é‡
        
        Args:
            close: æ”¶ç›˜ä»· Series
            period: è®¡ç®—å‘¨æœŸ
            
        Returns:
            Momentum Series
        """
        mom = close - close.shift(period)
        return mom.fillna(0)
    
    @staticmethod
    def calculate_williams_r(df: pd.DataFrame, period: int = 14) -> pd.Series:
        """
        è®¡ç®— Williams %R - å¨å»‰æŒ‡æ ‡
        
        Args:
            df: åŒ…å« high, low, close çš„ DataFrame
            period: è®¡ç®—å‘¨æœŸ
            
        Returns:
            Williams %R Series (-100 to 0)
        """
        high_n = df['high'].rolling(window=period).max()
        low_n = df['low'].rolling(window=period).min()
        
        wr = (high_n - df['close']) / (high_n - low_n) * -100
        return wr.fillna(-50)
    
    @staticmethod
    def calculate_cci(df: pd.DataFrame, period: int = 20) -> pd.Series:
        """
        è®¡ç®— CCI (Commodity Channel Index) - å•†å“é€šé“æŒ‡æ•°
        
        Args:
            df: åŒ…å« high, low, close çš„ DataFrame
            period: è®¡ç®—å‘¨æœŸ
            
        Returns:
            CCI Series
        """
        # å…¸å‹ä»·æ ¼
        tp = (df['high'] + df['low'] + df['close']) / 3
        
        # CCI = (TP - SMA(TP)) / (0.015 * MAD)
        sma_tp = tp.rolling(window=period).mean()
        mad = tp.rolling(window=period).apply(lambda x: np.abs(x - x.mean()).mean(), raw=True)
        
        cci = (tp - sma_tp) / (0.015 * mad)
        cci = cci.fillna(0)
        cci = cci.replace([np.inf, -np.inf], 0)
        
        return cci
    
    @staticmethod
    def calculate_adx(df: pd.DataFrame, period: int = 14) -> tuple:
        """
        è®¡ç®— ADX (Average Directional Index) - å¹³å‡è¶‹å‘æŒ‡æ•°
        
        Args:
            df: åŒ…å« high, low, close çš„ DataFrame
            period: è®¡ç®—å‘¨æœŸ
            
        Returns:
            (ADX, +DI, -DI) Series tuple
        """
        high = df['high']
        low = df['low']
        close = df['close']
        
        # True Range
        tr1 = high - low
        tr2 = abs(high - close.shift(1))
        tr3 = abs(low - close.shift(1))
        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
        
        # Directional Movement
        up_move = high - high.shift(1)
        down_move = low.shift(1) - low
        
        plus_dm = up_move.where((up_move > down_move) & (up_move > 0), 0)
        minus_dm = down_move.where((down_move > up_move) & (down_move > 0), 0)
        
        # Smoothed TR and DM
        atr = tr.ewm(alpha=1/period, adjust=False).mean()
        plus_di = 100 * (plus_dm.ewm(alpha=1/period, adjust=False).mean() / atr)
        minus_di = 100 * (minus_dm.ewm(alpha=1/period, adjust=False).mean() / atr)
        
        # DX and ADX
        dx = 100 * abs(plus_di - minus_di) / (plus_di + minus_di)
        adx = dx.ewm(alpha=1/period, adjust=False).mean()
        
        # å¤„ç†å¼‚å¸¸å€¼
        adx = adx.fillna(25)
        plus_di = plus_di.fillna(25)
        minus_di = minus_di.fillna(25)
        
        adx = adx.replace([np.inf, -np.inf], 25)
        plus_di = plus_di.replace([np.inf, -np.inf], 25)
        minus_di = minus_di.replace([np.inf, -np.inf], 25)
        
        return adx, plus_di, minus_di
    
    @staticmethod
    def calculate_stoch_rsi(close: pd.Series, rsi_period: int = 14, stoch_period: int = 14) -> tuple:
        """
        è®¡ç®— Stochastic RSI - éšæœº RSI
        
        Args:
            close: æ”¶ç›˜ä»· Series
            rsi_period: RSI å‘¨æœŸ
            stoch_period: éšæœºæŒ‡æ ‡å‘¨æœŸ
            
        Returns:
            (StochRSI_K, StochRSI_D) Series tuple
        """
        rsi = TechnicalIndicators.calculate_rsi(close, rsi_period)
        
        rsi_low = rsi.rolling(window=stoch_period).min()
        rsi_high = rsi.rolling(window=stoch_period).max()
        
        stoch_rsi_k = (rsi - rsi_low) / (rsi_high - rsi_low) * 100
        stoch_rsi_d = stoch_rsi_k.rolling(window=3).mean()
        
        stoch_rsi_k = stoch_rsi_k.fillna(50)
        stoch_rsi_d = stoch_rsi_d.fillna(50)
        
        return stoch_rsi_k, stoch_rsi_d


class FeatureExtractor:
    """ç‰¹å¾æå–å™¨"""
    
    def __init__(self):
        self.timeframes = ['5m', '15m', '30m', '1h', '4h', '1d']
        self.indicators = TechnicalIndicators()
    
    def extract_features(self, df_dict: Dict[str, pd.DataFrame]) -> pd.Series:
        """
        ä»å¤šæ—¶é—´å‘¨æœŸæ•°æ®ä¸­æå–ç‰¹å¾
        
        Args:
            df_dict: {'5m': df_5m, '15m': df_15m, ...}
            
        Returns:
            ç‰¹å¾ Series
        """
        features = {}
        
        for tf in self.timeframes:
            if tf not in df_dict or len(df_dict[tf]) < 50:
                continue
                
            df = df_dict[tf]
            
            # 1. è®¡ç®— KDJ
            k, d, j = self.indicators.calculate_kdj(df)
            
            # 2. è®¡ç®— MACD
            macd, signal, hist = self.indicators.calculate_macd(df['close'])
            
            # 3. è®¡ç®— RSI (å¤šå‘¨æœŸ)
            rsi_7 = self.indicators.calculate_rsi(df['close'], period=7)
            rsi_14 = self.indicators.calculate_rsi(df['close'], period=14)
            rsi_21 = self.indicators.calculate_rsi(df['close'], period=21)
            
            # 4. æ£€æµ‹äº¤å‰ä¿¡å·
            kdj_golden, kdj_death = self.indicators.detect_crossover(k, d)
            macd_golden, macd_death = self.indicators.detect_crossover(macd, signal)
            
            # 5. è®¡ç®—æ³¢åŠ¨ç‡ (å¹´åŒ–)
            returns = df['close'].pct_change()
            periods_per_year = {'5m': 288*365, '15m': 96*365, '30m': 48*365, '1h': 24*365, '4h': 6*365, '1d': 365}
            volatility = returns.std() * np.sqrt(periods_per_year.get(tf, 365))
            
            # 6. æˆäº¤é‡ç‰¹å¾ (Volume Features)
            volume = df['volume']
            volume_ma5 = volume.rolling(5).mean()
            volume_ma10 = volume.rolling(10).mean()
            volume_ma20 = volume.rolling(20).mean()
            
            # æˆäº¤é‡æ¯”ç‡ (å½“å‰æˆäº¤é‡ / MA)
            vol_ratio_ma5 = volume.iloc[-1] / volume_ma5.iloc[-1] if volume_ma5.iloc[-1] > 0 else 1
            vol_ratio_ma10 = volume.iloc[-1] / volume_ma10.iloc[-1] if volume_ma10.iloc[-1] > 0 else 1
            vol_ratio_ma20 = volume.iloc[-1] / volume_ma20.iloc[-1] if volume_ma20.iloc[-1] > 0 else 1
            
            # æˆäº¤é‡å˜åŒ–ç‡
            vol_change_1 = (volume.iloc[-1] - volume.iloc[-2]) / volume.iloc[-2] * 100 if volume.iloc[-2] > 0 else 0
            vol_change_5 = (volume.iloc[-1] - volume.iloc[-6]) / volume.iloc[-6] * 100 if len(volume) > 5 and volume.iloc[-6] > 0 else 0
            
            # æˆäº¤é‡è¶‹åŠ¿ (MA5 vs MA20)
            vol_trend = (volume_ma5.iloc[-1] - volume_ma20.iloc[-1]) / volume_ma20.iloc[-1] * 100 if volume_ma20.iloc[-1] > 0 else 0
            
            # æˆäº¤é‡ä½ç½® (ç›¸å¯¹äºæœ€è¿‘20æ ¹Kçº¿çš„é«˜ä½ç‚¹)
            vol_high_20 = volume.tail(20).max()
            vol_low_20 = volume.tail(20).min()
            vol_position = (volume.iloc[-1] - vol_low_20) / (vol_high_20 - vol_low_20) if vol_high_20 > vol_low_20 else 0.5
            
            # æˆäº¤é‡æ”¾å¤§ä¿¡å· (æ˜¯å¦è¶…è¿‡2å€MA)
            vol_spike = 1 if vol_ratio_ma20 > 2 else 0
            
            # æˆäº¤é‡èç¼©ä¿¡å· (æ˜¯å¦ä½äº0.5å€MA)
            vol_shrink = 1 if vol_ratio_ma20 < 0.5 else 0
            
            # é‡ä»·èƒŒç¦»æ£€æµ‹
            price_up = 1 if df['close'].iloc[-1] > df['close'].iloc[-2] else 0
            vol_up = 1 if volume.iloc[-1] > volume.iloc[-2] else 0
            vol_price_divergence = 1 if price_up != vol_up else 0  # ä»·æ¶¨é‡è·Œ æˆ– ä»·è·Œé‡æ¶¨
            
            # 7. ä»·æ ¼ä½ç½® (ç›¸å¯¹äºæœ€è¿‘ N æ ¹ K çº¿)
            recent_high = df['high'].tail(20).max()
            recent_low = df['low'].tail(20).min()
            price_position = (df['close'].iloc[-1] - recent_low) / (recent_high - recent_low) if recent_high > recent_low else 0.5
            
            # 8. è¶‹åŠ¿å¼ºåº¦ (ä»·æ ¼ä¸å‡çº¿çš„åç¦»)
            ma20 = df['close'].rolling(20).mean()
            trend_strength = (df['close'].iloc[-1] - ma20.iloc[-1]) / ma20.iloc[-1] * 100 if ma20.iloc[-1] > 0 else 0
            
            # 9. RSI è¡ç”Ÿç‰¹å¾
            rsi_14_value = rsi_14.iloc[-1]
            rsi_overbought = 1 if rsi_14_value > 70 else 0      # è¶…ä¹°
            rsi_oversold = 1 if rsi_14_value < 30 else 0        # è¶…å–
            rsi_trend = rsi_14.iloc[-1] - rsi_14.iloc[-5] if len(rsi_14) > 5 else 0  # RSI è¶‹åŠ¿
            
            # 10. é¢å¤–åŠ¨é‡æŒ‡æ ‡
            # ROC - ä»·æ ¼å˜åŒ–ç‡
            roc_5 = self.indicators.calculate_roc(df['close'], period=5)
            roc_10 = self.indicators.calculate_roc(df['close'], period=10)
            roc_20 = self.indicators.calculate_roc(df['close'], period=20)
            
            # MOM - åŠ¨é‡
            mom_10 = self.indicators.calculate_momentum(df['close'], period=10)
            mom_20 = self.indicators.calculate_momentum(df['close'], period=20)
            
            # Williams %R
            williams_r = self.indicators.calculate_williams_r(df, period=14)
            
            # CCI - å•†å“é€šé“æŒ‡æ•°
            cci = self.indicators.calculate_cci(df, period=20)
            
            # ADX - å¹³å‡è¶‹å‘æŒ‡æ•°
            adx, plus_di, minus_di = self.indicators.calculate_adx(df, period=14)
            
            # Stochastic RSI
            stoch_rsi_k, stoch_rsi_d = self.indicators.calculate_stoch_rsi(df['close'])
            
            # åŠ¨é‡æŒ‡æ ‡è¡ç”Ÿç‰¹å¾
            cci_value = cci.iloc[-1]
            cci_overbought = 1 if cci_value > 100 else 0
            cci_oversold = 1 if cci_value < -100 else 0
            
            adx_value = adx.iloc[-1]
            adx_strong_trend = 1 if adx_value > 25 else 0  # å¼ºè¶‹åŠ¿
            adx_weak_trend = 1 if adx_value < 20 else 0    # å¼±è¶‹åŠ¿/ç›˜æ•´
            
            # è¶‹åŠ¿æ–¹å‘ (+DI vs -DI)
            trend_bullish = 1 if plus_di.iloc[-1] > minus_di.iloc[-1] else 0
            
            # æ„å»ºç‰¹å¾
            tf_features = {
                # KDJ æŒ‡æ ‡
                f'{tf}_kdj_k': k.iloc[-1],
                f'{tf}_kdj_d': d.iloc[-1],
                f'{tf}_kdj_j': j.iloc[-1],
                f'{tf}_kdj_golden': int(kdj_golden.iloc[-1]) if not pd.isna(kdj_golden.iloc[-1]) else 0,
                f'{tf}_kdj_death': int(kdj_death.iloc[-1]) if not pd.isna(kdj_death.iloc[-1]) else 0,
                
                # MACD æŒ‡æ ‡
                f'{tf}_macd': macd.iloc[-1],
                f'{tf}_macd_signal': signal.iloc[-1],
                f'{tf}_macd_hist': hist.iloc[-1],
                f'{tf}_macd_golden': int(macd_golden.iloc[-1]) if not pd.isna(macd_golden.iloc[-1]) else 0,
                f'{tf}_macd_death': int(macd_death.iloc[-1]) if not pd.isna(macd_death.iloc[-1]) else 0,
                
                # æ³¢åŠ¨ç‡
                f'{tf}_volatility': volatility,
                
                # æˆäº¤é‡ç‰¹å¾ (Volume Features)
                f'{tf}_vol_ratio_ma5': vol_ratio_ma5,      # æˆäº¤é‡/MA5
                f'{tf}_vol_ratio_ma10': vol_ratio_ma10,    # æˆäº¤é‡/MA10
                f'{tf}_vol_ratio_ma20': vol_ratio_ma20,    # æˆäº¤é‡/MA20
                f'{tf}_vol_change_1': vol_change_1,        # 1æ ¹Kçº¿æˆäº¤é‡å˜åŒ–%
                f'{tf}_vol_change_5': vol_change_5,        # 5æ ¹Kçº¿æˆäº¤é‡å˜åŒ–%
                f'{tf}_vol_trend': vol_trend,              # æˆäº¤é‡è¶‹åŠ¿ (MA5 vs MA20)
                f'{tf}_vol_position': vol_position,        # æˆäº¤é‡ä½ç½® (0-1)
                f'{tf}_vol_spike': vol_spike,              # æ”¾é‡ä¿¡å·
                f'{tf}_vol_shrink': vol_shrink,            # ç¼©é‡ä¿¡å·
                f'{tf}_vol_price_divergence': vol_price_divergence,  # é‡ä»·èƒŒç¦»
                
                # ä»·æ ¼çŠ¶æ€
                f'{tf}_price_position': price_position,
                f'{tf}_trend_strength': trend_strength,
                
                # RSI æŒ‡æ ‡
                f'{tf}_rsi_7': rsi_7.iloc[-1],              # RSI(7) - çŸ­å‘¨æœŸ
                f'{tf}_rsi_14': rsi_14.iloc[-1],            # RSI(14) - æ ‡å‡†å‘¨æœŸ
                f'{tf}_rsi_21': rsi_21.iloc[-1],            # RSI(21) - é•¿å‘¨æœŸ
                f'{tf}_rsi_overbought': rsi_overbought,     # è¶…ä¹°ä¿¡å· (RSI > 70)
                f'{tf}_rsi_oversold': rsi_oversold,         # è¶…å–ä¿¡å· (RSI < 30)
                f'{tf}_rsi_trend': rsi_trend,               # RSI è¶‹åŠ¿å˜åŒ–
                
                # ROC - ä»·æ ¼å˜åŒ–ç‡
                f'{tf}_roc_5': roc_5.iloc[-1],              # ROC(5)
                f'{tf}_roc_10': roc_10.iloc[-1],            # ROC(10)
                f'{tf}_roc_20': roc_20.iloc[-1],            # ROC(20)
                
                # MOM - åŠ¨é‡
                f'{tf}_mom_10': mom_10.iloc[-1],            # Momentum(10)
                f'{tf}_mom_20': mom_20.iloc[-1],            # Momentum(20)
                
                # Williams %R
                f'{tf}_williams_r': williams_r.iloc[-1],    # Williams %R (-100 to 0)
                
                # CCI - å•†å“é€šé“æŒ‡æ•°
                f'{tf}_cci': cci.iloc[-1],                  # CCI å€¼
                f'{tf}_cci_overbought': cci_overbought,     # CCI è¶…ä¹° (>100)
                f'{tf}_cci_oversold': cci_oversold,         # CCI è¶…å– (<-100)
                
                # ADX - å¹³å‡è¶‹å‘æŒ‡æ•°
                f'{tf}_adx': adx.iloc[-1],                  # ADX å€¼
                f'{tf}_plus_di': plus_di.iloc[-1],          # +DI
                f'{tf}_minus_di': minus_di.iloc[-1],        # -DI
                f'{tf}_adx_strong_trend': adx_strong_trend, # å¼ºè¶‹åŠ¿ä¿¡å· (ADX > 25)
                f'{tf}_adx_weak_trend': adx_weak_trend,     # å¼±è¶‹åŠ¿ä¿¡å· (ADX < 20)
                f'{tf}_trend_bullish': trend_bullish,       # è¶‹åŠ¿çœ‹æ¶¨ (+DI > -DI)
                
                # Stochastic RSI
                f'{tf}_stoch_rsi_k': stoch_rsi_k.iloc[-1],  # Stoch RSI K
                f'{tf}_stoch_rsi_d': stoch_rsi_d.iloc[-1],  # Stoch RSI D
            }
            
            # æ¸…æ´—ç‰¹å¾å€¼
            for key, value in tf_features.items():
                if pd.isna(value) or np.isinf(value):
                    tf_features[key] = 0
            
            features.update(tf_features)
        
        # å¤šå‘¨æœŸå…±æŒ¯ç‰¹å¾
        golden_count = sum([features.get(f'{tf}_kdj_golden', 0) + features.get(f'{tf}_macd_golden', 0) for tf in self.timeframes])
        death_count = sum([features.get(f'{tf}_kdj_death', 0) + features.get(f'{tf}_macd_death', 0) for tf in self.timeframes])
        
        features['multi_tf_golden_count'] = golden_count
        features['multi_tf_death_count'] = death_count
        features['signal_strength'] = golden_count - death_count  # æ­£æ•°=çœ‹æ¶¨ï¼Œè´Ÿæ•°=çœ‹è·Œ
        
        # æ—¶é—´ç‰¹å¾
        now = datetime.now()
        features['hour'] = now.hour
        features['day_of_week'] = now.weekday()
        features['is_weekend'] = 1 if now.weekday() >= 5 else 0
        
        return pd.Series(features)


class LabelGenerator:
    """æ ‡ç­¾ç”Ÿæˆå™¨"""
    
    @staticmethod
    def generate_labels(df: pd.DataFrame, lookforward_periods: int = 20) -> pd.DataFrame:
        """
        ç”Ÿæˆæœªæ¥ä»·æ ¼å˜åŠ¨æ ‡ç­¾
        
        Args:
            df: åŒ…å« close çš„ DataFrame
            lookforward_periods: é¢„æµ‹æœªæ¥å¤šå°‘æ ¹ K çº¿
            
        Returns:
            æ·»åŠ äº†æ ‡ç­¾çš„ DataFrame
        """
        df = df.copy()
        
        # æœªæ¥ä»·æ ¼
        future_price = df['close'].shift(-lookforward_periods)
        current_price = df['close']
        
        # ä»·æ ¼å˜åŠ¨ç™¾åˆ†æ¯”
        price_change_pct = (future_price - current_price) / current_price * 100
        
        # å›å½’ç›®æ ‡
        df['target_regression'] = price_change_pct
        
        # åˆ†ç±»ç›®æ ‡
        def classify_change(pct):
            if pd.isna(pct):
                return np.nan
            elif pct < -2:
                return 0  # å¤§è·Œ
            elif pct < -0.5:
                return 1  # å°è·Œ
            elif pct < 0.5:
                return 2  # æ¨ªç›˜
            elif pct < 2:
                return 3  # å°æ¶¨
            else:
                return 4  # å¤§æ¶¨
        
        df['target_classification'] = price_change_pct.apply(classify_change)
        
        # æ–¹å‘ç›®æ ‡ (ç®€åŒ–ç‰ˆ)
        df['target_direction'] = np.where(price_change_pct > 0, 1, np.where(price_change_pct < 0, -1, 0))
        
        return df


class DataCollector:
    """ä¸»æ•°æ®æ”¶é›†å™¨"""
    
    def __init__(self, symbol: str = 'BTCUSDT', output_dir: str = './data'):
        self.symbol = symbol
        self.output_dir = output_dir
        
        self.fetcher = BinanceDataFetcher(symbol)
        self.feature_extractor = FeatureExtractor()
        self.label_generator = LabelGenerator()
        
        os.makedirs(output_dir, exist_ok=True)
    
    def collect_snapshot(self) -> dict:
        """æ”¶é›†å½“å‰æ—¶åˆ»çš„æ•°æ®å¿«ç…§"""
        print(f"\nğŸš€ å¼€å§‹æ”¶é›† {self.symbol} æ•°æ®å¿«ç…§...")
        print(f"   æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # 1. è·å–æ‰€æœ‰æ—¶é—´å‘¨æœŸæ•°æ®
        print("\nğŸ“Š è·å– K çº¿æ•°æ®...")
        df_dict = self.fetcher.get_all_timeframes(limit=200)
        
        # 2. è·å–èµ„é‡‘è´¹ç‡
        print("\nğŸ’° è·å–èµ„é‡‘è´¹ç‡...")
        funding = self.fetcher.get_funding_rate()
        print(f"   èµ„é‡‘è´¹ç‡: {funding['funding_rate']*100:.4f}%")
        print(f"   æ ‡è®°ä»·æ ¼: {funding['mark_price']:,.2f}")
        print(f"   æŒ‡æ•°ä»·æ ¼: {funding['index_price']:,.2f}")
        
        # 3. æå–ç‰¹å¾
        print("\nğŸ”§ æå–ç‰¹å¾...")
        features = self.feature_extractor.extract_features(df_dict)
        features['funding_rate'] = funding['funding_rate']
        features['mark_price'] = funding['mark_price']
        features['index_price'] = funding['index_price']
        features['timestamp'] = datetime.now().isoformat()
        
        # 4. æ‰“å°ä¿¡å·æ‘˜è¦
        self._print_signal_summary(features)
        
        return {
            'features': features,
            'klines': df_dict,
            'funding': funding
        }
    
    def _print_signal_summary(self, features: pd.Series):
        """æ‰“å°ä¿¡å·æ‘˜è¦"""
        print("\n" + "=" * 60)
        print("ğŸ“ˆ ä¿¡å·æ‘˜è¦")
        print("=" * 60)
        
        # KDJ/MACD äº¤å‰ä¿¡å·
        for tf in ['5m', '15m', '1h', '4h', '1d']:
            kdj_g = features.get(f'{tf}_kdj_golden', 0)
            kdj_d = features.get(f'{tf}_kdj_death', 0)
            macd_g = features.get(f'{tf}_macd_golden', 0)
            macd_d = features.get(f'{tf}_macd_death', 0)
            
            signals = []
            if kdj_g: signals.append("KDJé‡‘å‰ğŸŸ¢")
            if kdj_d: signals.append("KDJæ­»å‰ğŸ”´")
            if macd_g: signals.append("MACDé‡‘å‰ğŸŸ¢")
            if macd_d: signals.append("MACDæ­»å‰ğŸ”´")
            
            if signals:
                print(f"  {tf:>3}: {', '.join(signals)}")
        
        # å¤šå‘¨æœŸå…±æŒ¯
        signal_strength = features.get('signal_strength', 0)
        if signal_strength > 0:
            print(f"\n  ğŸ”¥ å¤šå‘¨æœŸå…±æŒ¯: çœ‹æ¶¨ (+{signal_strength})")
        elif signal_strength < 0:
            print(f"\n  ğŸ”¥ å¤šå‘¨æœŸå…±æŒ¯: çœ‹è·Œ ({signal_strength})")
        else:
            print(f"\n  âš–ï¸ å¤šå‘¨æœŸå…±æŒ¯: ä¸­æ€§ (0)")
        
        print("=" * 60)
    
    def collect_historical_features(self, base_timeframe: str = '1h', 
                                     lookforward: int = 20,
                                     lookback: int = 100,
                                     start_date: str = None,
                                     end_date: str = None) -> pd.DataFrame:
        """
        æ”¶é›†å†å²ç‰¹å¾æ•°æ®ç”¨äºæ¨¡å‹è®­ç»ƒ
        
        Args:
            base_timeframe: åŸºå‡†æ—¶é—´å‘¨æœŸ
            lookforward: é¢„æµ‹æœªæ¥å¤šå°‘æ ¹ K çº¿
            lookback: å›æº¯å¤šå°‘ä¸ªæ•°æ®ç‚¹
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
            
        Returns:
            åŒ…å«ç‰¹å¾å’Œæ ‡ç­¾çš„ DataFrame
        """
        print(f"\nğŸš€ å¼€å§‹æ”¶é›†å†å²ç‰¹å¾æ•°æ®...")
        print(f"   åŸºå‡†å‘¨æœŸ: {base_timeframe}")
        print(f"   é¢„æµ‹å‘¨æœŸ: {lookforward} æ ¹ K çº¿")
        if start_date:
            print(f"   æ—¥æœŸèŒƒå›´: {start_date} ~ {end_date or 'ç°åœ¨'}")
        
        # è·å–æ•°æ®
        if start_date:
            df_dict = self.fetcher.get_all_timeframes_historical(start_date, end_date)
        else:
            df_dict = self.fetcher.get_all_timeframes(limit=500)
        
        # åŸºå‡†æ—¶é—´å‘¨æœŸæ•°æ®
        base_df = df_dict[base_timeframe].copy()
        
        # ç”Ÿæˆæ ‡ç­¾
        base_df = self.label_generator.generate_labels(base_df, lookforward)
        
        # æ”¶é›†æ¯ä¸ªæ—¶é—´ç‚¹çš„ç‰¹å¾
        features_list = []
        valid_indices = range(100, len(base_df) - lookforward)
        
        print(f"\nğŸ“Š æå– {len(valid_indices)} ä¸ªæ—¶é—´ç‚¹çš„ç‰¹å¾...")
        
        for i, idx in enumerate(valid_indices):
            # æˆªå–å†å²æ•°æ®
            current_df_dict = {}
            for tf, df in df_dict.items():
                # ç®€åŒ–å¤„ç†ï¼šä½¿ç”¨å›ºå®šçª—å£
                end_idx = min(idx + 1, len(df))
                start_idx = max(0, end_idx - 100)
                current_df_dict[tf] = df.iloc[start_idx:end_idx]
            
            # æå–ç‰¹å¾
            features = self.feature_extractor.extract_features(current_df_dict)
            
            # æ·»åŠ æ ‡ç­¾
            features['target_regression'] = base_df.iloc[idx]['target_regression']
            features['target_classification'] = base_df.iloc[idx]['target_classification']
            features['target_direction'] = base_df.iloc[idx]['target_direction']
            features['base_timestamp'] = base_df.iloc[idx]['timestamp']
            features['close_price'] = base_df.iloc[idx]['close']
            
            features_list.append(features)
            
            # è¿›åº¦æ˜¾ç¤º
            if (i + 1) % 50 == 0:
                print(f"   å·²å¤„ç†: {i + 1}/{len(valid_indices)}")
        
        result_df = pd.DataFrame(features_list)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        filename = f"{self.symbol}_features_{base_timeframe}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        filepath = os.path.join(self.output_dir, filename)
        result_df.to_csv(filepath, index=False)
        print(f"\nğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {filepath}")
        print(f"   æ ·æœ¬æ•°é‡: {len(result_df)}")
        print(f"   ç‰¹å¾æ•°é‡: {len(result_df.columns)}")
        
        # æ‰“å°æ ‡ç­¾åˆ†å¸ƒ
        if 'target_classification' in result_df.columns:
            print("\nğŸ“Š æ ‡ç­¾åˆ†å¸ƒ:")
            labels = {0: 'å¤§è·Œ', 1: 'å°è·Œ', 2: 'æ¨ªç›˜', 3: 'å°æ¶¨', 4: 'å¤§æ¶¨'}
            for label, name in labels.items():
                count = (result_df['target_classification'] == label).sum()
                pct = count / len(result_df) * 100
                print(f"   {name}: {count} ({pct:.1f}%)")
        
        return result_df


def main():
    parser = argparse.ArgumentParser(description='BTC ä»·æ ¼å˜åŠ¨é¢„æµ‹ - æ•°æ®æ”¶é›†å™¨')
    parser.add_argument('--symbol', type=str, default='BTCUSDT', help='äº¤æ˜“å¯¹')
    parser.add_argument('--output', type=str, default='../data', help='æ•°æ®ä¿å­˜ç›®å½•')
    parser.add_argument('--mode', type=str, choices=['snapshot', 'historical'], default='snapshot',
                        help='æ¨¡å¼: snapshot=å½“å‰å¿«ç…§, historical=å†å²ç‰¹å¾')
    parser.add_argument('--timeframe', type=str, default='1h', help='å†å²æ¨¡å¼çš„åŸºå‡†æ—¶é—´å‘¨æœŸ')
    parser.add_argument('--lookforward', type=int, default=20, help='é¢„æµ‹æœªæ¥å¤šå°‘æ ¹Kçº¿')
    parser.add_argument('--start-date', type=str, default=None, help='å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)')
    parser.add_argument('--end-date', type=str, default=None, help='ç»“æŸæ—¥æœŸ (YYYY-MM-DD)')
    
    args = parser.parse_args()
    
    collector = DataCollector(symbol=args.symbol, output_dir=args.output)
    
    if args.mode == 'snapshot':
        # æ”¶é›†å½“å‰å¿«ç…§
        data = collector.collect_snapshot()
        
        # ä¿å­˜ç‰¹å¾å¿«ç…§
        features_df = pd.DataFrame([data['features']])
        filename = f"{args.symbol}_snapshot_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        filepath = os.path.join(args.output, filename)
        features_df.to_csv(filepath, index=False)
        print(f"\nğŸ’¾ å¿«ç…§å·²ä¿å­˜åˆ°: {filepath}")
        
    elif args.mode == 'historical':
        # æ”¶é›†å†å²ç‰¹å¾
        collector.collect_historical_features(
            base_timeframe=args.timeframe,
            lookforward=args.lookforward,
            start_date=args.start_date,
            end_date=args.end_date
        )


if __name__ == "__main__":
    main()

